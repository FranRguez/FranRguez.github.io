{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION IN BREACHES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'Windows-1252', 'confidence': 0.7019810807872132, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "with open(\"prcbreaches2005-18.csv\", 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(10000))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We see the test most suitable encoding for our data is Windows-1252."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Records.Breached</th>\n",
       "      <th>Records.Breached...Detail</th>\n",
       "      <th>Name</th>\n",
       "      <th>CatID</th>\n",
       "      <th>Total.Records</th>\n",
       "      <th>Region</th>\n",
       "      <th>Contact..etc.</th>\n",
       "      <th>Category_dm</th>\n",
       "      <th>Entity_prc</th>\n",
       "      <th>State</th>\n",
       "      <th>OrgID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date.Made.Public</th>\n",
       "      <th>Year</th>\n",
       "      <th>Source.of.Breach.Notification</th>\n",
       "      <th>Type</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Dean Health Plan</td>\n",
       "      <td>28</td>\n",
       "      <td>1,311</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Discharge Data</td>\n",
       "      <td>MED</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>200003106</td>\n",
       "      <td></td>\n",
       "      <td>15-Jun-18</td>\n",
       "      <td>2018</td>\n",
       "      <td>US Department of Health and Human Services</td>\n",
       "      <td>DISC</td>\n",
       "      <td>Location of breached information: Paper/Films\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>HealthEquity, Inc.</td>\n",
       "      <td>28</td>\n",
       "      <td>16,000</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Discharge Data</td>\n",
       "      <td>MED</td>\n",
       "      <td>Utah</td>\n",
       "      <td>200003107</td>\n",
       "      <td></td>\n",
       "      <td>12-Jun-18</td>\n",
       "      <td>2018</td>\n",
       "      <td>US Department of Health and Human Services</td>\n",
       "      <td>HACK</td>\n",
       "      <td>Location of breached information: Email\\nBusin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Ticketfly</td>\n",
       "      <td>15</td>\n",
       "      <td>27,000,000</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Employer</td>\n",
       "      <td>BSR</td>\n",
       "      <td>California</td>\n",
       "      <td>200003097</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>12-Jun-18</td>\n",
       "      <td>2018</td>\n",
       "      <td>Media</td>\n",
       "      <td>HACK</td>\n",
       "      <td>Ticketfly was the target of a malicious cyber ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>PageUp</td>\n",
       "      <td>17</td>\n",
       "      <td>2,000,000</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Payer (Insurer)</td>\n",
       "      <td>BSO</td>\n",
       "      <td></td>\n",
       "      <td>200003099</td>\n",
       "      <td></td>\n",
       "      <td>12-Jun-18</td>\n",
       "      <td>2018</td>\n",
       "      <td>Media</td>\n",
       "      <td>HACK</td>\n",
       "      <td>TechRadar reports:PageUp, an Australia-based s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Facebook, inc.</td>\n",
       "      <td>17</td>\n",
       "      <td>3,000,000</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Payer (Insurer)</td>\n",
       "      <td>BSR</td>\n",
       "      <td>California</td>\n",
       "      <td>200003102</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>12-Jun-18</td>\n",
       "      <td>2018</td>\n",
       "      <td>Media</td>\n",
       "      <td>DISC</td>\n",
       "      <td>New Scientist reports:DataÎŒŠ—¾from millions o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Records.Breached Records.Breached...Detail                Name CatID  \\\n",
       "0               NA                        NA    Dean Health Plan    28   \n",
       "0               NA                        NA  HealthEquity, Inc.    28   \n",
       "0               NA                        NA           Ticketfly    15   \n",
       "0               NA                        NA              PageUp    17   \n",
       "0               NA                        NA      Facebook, inc.    17   \n",
       "\n",
       "  Total.Records Region Contact..etc.      Category_dm Entity_prc       State  \\\n",
       "0         1,311     NA            NA   Discharge Data        MED   Wisconsin   \n",
       "0        16,000     NA            NA   Discharge Data        MED        Utah   \n",
       "0    27,000,000     NA            NA         Employer        BSR  California   \n",
       "0     2,000,000     NA            NA  Payer (Insurer)        BSO               \n",
       "0     3,000,000     NA            NA  Payer (Insurer)        BSR  California   \n",
       "\n",
       "       OrgID       Location Date.Made.Public  Year  \\\n",
       "0  200003106                       15-Jun-18  2018   \n",
       "0  200003107                       12-Jun-18  2018   \n",
       "0  200003097  San Francisco        12-Jun-18  2018   \n",
       "0  200003099                       12-Jun-18  2018   \n",
       "0  200003102  San Francisco        12-Jun-18  2018   \n",
       "\n",
       "                Source.of.Breach.Notification  Type  \\\n",
       "0  US Department of Health and Human Services  DISC   \n",
       "0  US Department of Health and Human Services  HACK   \n",
       "0                                       Media  HACK   \n",
       "0                                       Media  HACK   \n",
       "0                                       Media  DISC   \n",
       "\n",
       "                                         Description  \n",
       "0  Location of breached information: Paper/Films\\...  \n",
       "0  Location of breached information: Email\\nBusin...  \n",
       "0  Ticketfly was the target of a malicious cyber ...  \n",
       "0  TechRadar reports:PageUp, an Australia-based s...  \n",
       "0  New Scientist reports:DataÎŒŠ—¾from millions o...  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "index=pd.DataFrame(columns=['Holi'])\n",
    "with open('prcbreaches2005-18.csv', 'r', encoding='Windows-1252', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    cols=pd.DataFrame(columns=['Holi'])\n",
    "    x=0\n",
    "    # Defining the columns in my DataFrame\n",
    "    for j in spamreader:\n",
    "        if x==0:\n",
    "            cols=j\n",
    "            index=pd.DataFrame(columns=cols)\n",
    "            x+=1\n",
    "        else:\n",
    "            index=index.append(pd.DataFrame([j], columns=cols))\n",
    "            \n",
    "index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the heterogeneous date format in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "fechameses=pd.DataFrame()\n",
    "fechamesesydia=pd.DataFrame()\n",
    "index['Date.Made.Public'] = pd.to_datetime(index['Date.Made.Public'])\n",
    "for i in index['Date.Made.Public']:\n",
    "    daymonth=i.strftime(\"%m-%d\")\n",
    "    fechamesesydia=fechamesesydia.append(pd.DataFrame([daymonth], columns=['monthandday_date']))\n",
    "    month=i.strftime(\"%m\")\n",
    "    fechameses=fechameses.append(pd.DataFrame([month], columns=['month_date']))\n",
    "    \n",
    "index['monthandday_date']=fechamesesydia['monthandday_date']\n",
    "index['month_date']=fechameses['month_date']\n",
    "index.head()\n",
    "\n",
    "# Let's convert to numeric the column Records.breached, as it is now string.\n",
    "index['Records.Breached']=index['Records.Breached'].replace('NA','')\n",
    "index['Records.Breached']=pd.to_numeric(index['Records.Breached'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day of the week visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As it is could be understandable, the dates breaches are made public are consistently less common in non-working days. Thus, in order to represent the frequency, we might be interested in excluding them for some time analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays=pd.DataFrame()\n",
    "for i in index['Date.Made.Public']:\n",
    "    dayoftheweek=i.strftime(\"%A\")\n",
    "    weekdays=weekdays.append(pd.DataFrame([dayoftheweek], columns=['numberofday']))\n",
    "\n",
    "weekdays=weekdays.reset_index().groupby('numberofday').count()\n",
    "    \n",
    "\n",
    "# Sorting the values to begin on Sunday, and visualize it correctly.\n",
    "letssort = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "sortIndex = dict(zip(letssort,range(len(letssort))))\n",
    "sortIndex\n",
    "weekdays['nameofday'] = weekdays.index.map(sortIndex)  \n",
    "weekdays.sort_values('numberofday', inplace=True)\n",
    "\n",
    "weekdays.to_csv('weekdays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nameofday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numberofday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>1115</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>157</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>775</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index  nameofday\n",
       "numberofday                  \n",
       "Friday        1115          5\n",
       "Monday         667          1\n",
       "Saturday       157          6\n",
       "Sunday          74          0\n",
       "Thursday       775          4"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daymonth_onlyworkdays=pd.DataFrame()\n",
    "for i in index['Date.Made.Public']:\n",
    "    if int(i.strftime(\"%u\")) <=5:\n",
    "        onlyworkdays=i.strftime(\"%m-%d\")\n",
    "        daymonth_onlyworkdays=daymonth_onlyworkdays.append(pd.DataFrame([onlyworkdays], columns=['onlyworkdays']))\n",
    "fechasmeses=daymonth_onlyworkdays.reset_index().groupby('onlyworkdays').count()\n",
    "\n",
    "\n",
    "weekdays.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "fechasmeses=index.groupby('month_date').count()\n",
    "fechasmesesydias=index.groupby('monthandday_date').count()\n",
    "\n",
    "\n",
    "fechasmeses=pd.concat([fechasmeses['monthandday_date'], fechasmeses['Name']], axis=1)\n",
    "fechasmesesydias=pd.concat([fechasmesesydias['month_date'], fechasmesesydias['Name']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "index[1:].to_csv('pruebasbreaches.csv')\n",
    "fechasmeses.to_csv('pruebasbreaches_fechasmeses.csv')\n",
    "fechasmesesydias.to_csv('pruebasbreaches_fechasmesesydias.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node graphs visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First let's convet CatID to integers.\n",
    "index['CatID']=pd.to_numeric(index['CatID'])\n",
    "index.sort_values('CatID', inplace=True)\n",
    "# Did we do it correctly?\n",
    "index.head()\n",
    "\n",
    "# Let's count number of breaches reported by CatID.\n",
    "countbreachesbycatID=index.groupby('CatID').count()\n",
    "countbreachesbycatID=countbreachesbycatID.filter(['Name'])\n",
    "\n",
    "# Let's also count records breached by CatID:\n",
    "countrecordsbycatID=index.groupby('CatID').sum()\n",
    "countrecordsbycatID=countrecordsbycatID.filter(['Records.Breached'])\n",
    "countcatids=pd.merge(countrecordsbycatID, countbreachesbycatID, right_index=True, left_index=True)\n",
    "\n",
    "# Some CatIDs are not represented in our database, so let's merge it with the information dataset we've been provided.\n",
    "categories = pd.read_csv('C:/Users/Fran/Trabajo-ENS/Harvard TheDataMap/Nueva carpeta/categories.csv', sep=',', encoding='Windows-1252')\n",
    "mergecatids=pd.merge(categories, countcatids, left_on='CatID', right_index=True, how='outer')\n",
    "# Let's replace by 0 the values of the CatIDs which did not report any breach, or whose breaches did not report records breached.\n",
    "mergecatids['Name'].fillna(value=0.0, inplace=True)\n",
    "mergecatids['Records.Breached'].fillna(value=0.0, inplace=True)\n",
    "mergecatids.to_json('nodes.json', orient='records')\n",
    "\n",
    "edges = pd.read_excel(io='C:/Users/Fran/Trabajo-ENS/Harvard TheDataMap/Nueva carpeta/edges.xlsx')\n",
    "edges.columns=(['source', 'target', 'noname'])\n",
    "edges.to_json('edges.json', orient='records')\n",
    "\n",
    "\n",
    "with open('edges.json', 'r') as f:\n",
    "    edgesjson=json.load(f)\n",
    "with open('nodes.json', 'r') as f:\n",
    "    nodesjson=json.load(f)\n",
    "datajson={'nodes': nodesjson, 'edges': edgesjson}\n",
    "with open('nodegraphdata.json', 'w') as outfile:\n",
    "    json.dump(datajson, outfile)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US States map visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State\n",
      "                         30\n",
      "Alabama                  45\n",
      "Alaska                   12\n",
      "Argentina                 1\n",
      "Arizona                  69\n",
      "Arkansas                 31\n",
      "Beijing                   1\n",
      "Berlin                    1\n",
      "British Columbia          3\n",
      "Buckinghamshire           2\n",
      "California              756\n",
      "Cheshire                  1\n",
      "Colorado                 76\n",
      "Connecticut              58\n",
      "Delaware                  9\n",
      "District Of Columbia     53\n",
      "Dublin                    1\n",
      "Florida                 212\n",
      "Georgia                 111\n",
      "Grand Bahama              1\n",
      "Guangdong                 1\n",
      "Hawaii                   10\n",
      "Idaho                    10\n",
      "Illinois                153\n",
      "Indiana                  96\n",
      "Iowa                     35\n",
      "Kansas                   31\n",
      "Kentucky                 62\n",
      "London                    1\n",
      "Louisiana                28\n",
      "                       ... \n",
      "Missouri                 70\n",
      "Montana                  14\n",
      "Nebraska                 12\n",
      "Nevada                   30\n",
      "New Hampshire            20\n",
      "New Jersey               68\n",
      "New Mexico               24\n",
      "New York                266\n",
      "North Carolina           88\n",
      "North Dakota              5\n",
      "Ohio                    118\n",
      "Oklahoma                 35\n",
      "Ontario                   7\n",
      "Oregon                   63\n",
      "Pennsylvania            136\n",
      "Puerto Rico              12\n",
      "Quebec                    3\n",
      "Rhode Island             21\n",
      "South Carolina           32\n",
      "South Dakota              7\n",
      "Tennessee                85\n",
      "Texas                   292\n",
      "Tokyo                     1\n",
      "Utah                     32\n",
      "Vermont                   7\n",
      "Virginia                 89\n",
      "Washington              104\n",
      "West Virginia             8\n",
      "Wisconsin                55\n",
      "Wyoming                   8\n",
      "Name: Name, Length: 66, dtype: int64\n",
      "State\n",
      "                         5229249.0\n",
      "Alabama                   637247.0\n",
      "Alaska                       816.0\n",
      "Argentina                      0.0\n",
      "Arizona                   207875.0\n",
      "Arkansas                   10800.0\n",
      "Beijing                        0.0\n",
      "Berlin                         0.0\n",
      "British Columbia               0.0\n",
      "Buckinghamshire                0.0\n",
      "California               8477512.0\n",
      "Cheshire                       0.0\n",
      "Colorado                   57147.0\n",
      "Connecticut              1595326.0\n",
      "Delaware                 1600000.0\n",
      "District Of Columbia    76138641.0\n",
      "Dublin                         0.0\n",
      "Florida                  4098673.0\n",
      "Georgia                  3745161.0\n",
      "Grand Bahama                   0.0\n",
      "Guangdong                      0.0\n",
      "Hawaii                    170000.0\n",
      "Idaho                          0.0\n",
      "Illinois                  402861.0\n",
      "Indiana                  1329792.0\n",
      "Iowa                       33789.0\n",
      "Kansas                     12200.0\n",
      "Kentucky                   77389.0\n",
      "London                         0.0\n",
      "Louisiana                    416.0\n",
      "                           ...    \n",
      "Missouri                 1716065.0\n",
      "Montana                        0.0\n",
      "Nebraska                    3000.0\n",
      "Nevada                    135551.0\n",
      "New Hampshire             246870.0\n",
      "New Jersey                316171.0\n",
      "New Mexico                 15580.0\n",
      "New York                 3631837.0\n",
      "North Carolina            352208.0\n",
      "North Dakota                   0.0\n",
      "Ohio                      843534.0\n",
      "Oklahoma                  239674.0\n",
      "Ontario                        0.0\n",
      "Oregon                    433341.0\n",
      "Pennsylvania              277794.0\n",
      "Puerto Rico                 1691.0\n",
      "Quebec                         0.0\n",
      "Rhode Island               79962.0\n",
      "South Carolina            416789.0\n",
      "South Dakota                   0.0\n",
      "Tennessee                 886702.0\n",
      "Texas                     360439.0\n",
      "Tokyo                          0.0\n",
      "Utah                     1591400.0\n",
      "Vermont                        0.0\n",
      "Virginia                  542902.0\n",
      "Washington                 57859.0\n",
      "West Virginia              27218.0\n",
      "Wisconsin                 383633.0\n",
      "Wyoming                    14000.0\n",
      "Name: Records.Breached, Length: 66, dtype: float64\n",
      "Index(['Records.Breached', 'Name'], dtype='object')\n",
      "Worked with Alabama\n",
      "Worked with Alaska\n",
      "Worked with Arizona\n",
      "Worked with Arkansas\n",
      "Worked with California\n",
      "Worked with Colorado\n",
      "Worked with Connecticut\n",
      "Worked with Delaware\n",
      "Worked with District of Columbia\n",
      "Worked with Florida\n",
      "Worked with Georgia\n",
      "Worked with Hawaii\n",
      "Worked with Idaho\n",
      "Worked with Illinois\n",
      "Worked with Indiana\n",
      "Worked with Iowa\n",
      "Worked with Kansas\n",
      "Worked with Kentucky\n",
      "Worked with Louisiana\n",
      "Worked with Maine\n",
      "Worked with Maryland\n",
      "Worked with Massachusetts\n",
      "Worked with Michigan\n",
      "Worked with Minnesota\n",
      "Worked with Mississippi\n",
      "Worked with Missouri\n",
      "Worked with Montana\n",
      "Worked with Nebraska\n",
      "Worked with Nevada\n",
      "Worked with New Hampshire\n",
      "Worked with New Jersey\n",
      "Worked with New Mexico\n",
      "Worked with New York\n",
      "Worked with North Carolina\n",
      "Worked with North Dakota\n",
      "Worked with Ohio\n",
      "Worked with Oklahoma\n",
      "Worked with Oregon\n",
      "Worked with Pennsylvania\n",
      "Worked with Puerto Rico\n",
      "Worked with Rhode Island\n",
      "Worked with South Carolina\n",
      "Worked with South Dakota\n",
      "Worked with Tennessee\n",
      "Worked with Texas\n",
      "Worked with Utah\n",
      "Worked with Vermont\n",
      "Worked with Virginia\n",
      "Worked with Washington\n",
      "Worked with West Virginia\n",
      "Worked with Wisconsin\n",
      "Worked with Wyoming\n"
     ]
    }
   ],
   "source": [
    "#Let's first summarize number of breaches by state.\n",
    "countrecordsperstate=index.groupby('State').count()\n",
    "countrecordsperstate2=countrecordsperstate['Name']\n",
    "print(countrecordsperstate2)\n",
    "\n",
    "# Although we won't use the sum of records in the US states viz, the info could be useful for further visualizations.\n",
    "sumrecordsperstate=index.groupby('State').sum()\n",
    "sumrecordsperstate2=sumrecordsperstate['Records.Breached']\n",
    "print(sumrecordsperstate2)\n",
    "\n",
    "holi=pd.concat([sumrecordsperstate2, countrecordsperstate2],  axis=1)\n",
    "print(holi.columns)\n",
    "holi.columns=['numberofrecords', 'numberofbreaches']\n",
    "holi.to_csv('statescount.csv')\n",
    "\n",
    "\n",
    "# Now let's merge with the spatial shapefile we already have. \n",
    "import os\n",
    "import re\n",
    "\n",
    "with open('C:/Users/Fran/Trabajo-ENS/Harvard TheDataMap/Nueva carpeta/NuevoenGitHub/us-states.js') as dataFile:\n",
    "    data = dataFile.read()\n",
    "    # I want to only extract the variable information. In the end, we'll put it back.\n",
    "    obj = data[data.find('{'):data.rfind('}')+1]\n",
    "    jsonObj = json.loads(obj)\n",
    "    \n",
    "with open('statescount.csv', 'r') as csvfile_states:\n",
    "    spamreader = csv.reader(csvfile_states, delimiter=',')\n",
    "    x=0\n",
    "    # Defining the columns in my DataFrame\n",
    "    for j in spamreader:\n",
    "        if x==0:\n",
    "            cols=j\n",
    "            index=pd.DataFrame(columns=cols)\n",
    "            x+=1\n",
    "        else:\n",
    "            index=index.append(pd.DataFrame([j], columns=cols))\n",
    "            \n",
    "# now that it's already been built, let's jump to merge both.\n",
    "index=index.replace('District Of Columbia', 'District of Columbia')\n",
    "j=0\n",
    "for h in index['State']:\n",
    "    probemos=index['numberofbreaches'].iloc[j]\n",
    "    j+=1\n",
    "    for i in jsonObj['features']:\n",
    "        if i['properties']['name']==h:\n",
    "            print(\"Worked with \" + i['properties']['name'])\n",
    "            i['properties']={'name': h, 'density': i['properties']['density'], 'numberofbreaches': int(probemos)}\n",
    "            \n",
    "f = open(\"C:/Users/Fran/Trabajo-ENS/Harvard TheDataMap/Nueva carpeta/NuevoenGitHub/us-states2.js\", 'w')\n",
    "f.write(\"var statesData = \" + str(jsonObj))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
